{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581443cd-3bf2-492c-9d44-652c4090e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries that are needed\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "import os\n",
    "import pinecone\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60382de7-437f-4521-9a6a-5c0af2daa292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document that you need to parse\n",
    "loader = UnstructuredPDFLoader(\"/mnt/ETF_Docs/Select_Global_Value_Fund.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c2389-7da7-4f49-bff9-37279daeb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some stats about the document\n",
    "print (f'You have {len(data)} document(s) in the dataset')\n",
    "print (f'There are {len(data[0].page_content)} characters in the document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e942d3-87a2-4b23-9ea8-5db321cea8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk your data up into smaller documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89ce09-cc2c-48e7-aa51-017457d70c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'There are now {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0d06f-3daa-4c82-9e91-7db8739227c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embeddings of your documents to get ready for semantic search\n",
    "\n",
    "# Read your OpenAI key from the environment\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') \n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbbb23-316b-4c21-b762-18b43eb11a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pinecone\n",
    "\n",
    "# PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "# PINECONE_API_ENV = os.getenv('PINECONE_API_ENV')\n",
    "\n",
    "# # initialize pinecone\n",
    "# pinecone.init(\n",
    "#     api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "#     environment=PINECONE_API_ENV  # next to api key in console\n",
    "# )\n",
    "# index_name = \"vanguard-etf\"\n",
    "\n",
    "# # Generate and store the embeddings in Pinecone\n",
    "# docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18942653-32c7-4a78-ab05-db1c6b76aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index and store the embeddings locally in a pickle file\n",
    "store = FAISS.from_texts([t.page_content for t in texts], embeddings)\n",
    "with open(\"faiss_etf_doc_store.pkl\", \"wb\") as f:\n",
    "    pickle.dump(store, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19610f07-cf90-40f6-a1ae-0ff33e4ae015",
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad3073-df19-4695-86ba-c61bf1256de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions about information in Vanguards ETF documentation.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about investments, economics, finance or ML or or related to Vanguard, politely inform them that you are tuned to only answer questions about the finance industry.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e443d-ac3f-4645-8137-d72063f72ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from the pickle file; change the location if needed\n",
    "if 'store' not in locals() or store is None:\n",
    "    with open(\"faiss_etf_doc_store.pkl\", \"rb\") as f:\n",
    "        store = pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4213d-c00c-44e7-8e28-aeb83c79664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_history(inputs) -> str:\n",
    "    res = []\n",
    "    for human, ai in inputs:\n",
    "        res.append(f\"Human:{human}\\nAI:{ai}\")\n",
    "    return \"\\n\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8341a-cd0f-4744-9790-0b83d00a812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have a Pinecone Index, you can load it like this\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "# store = None\n",
    "# check if index already exists, if not we create it\n",
    "# if index_name in pinecone.list_indexes():\n",
    "    # connect to index\n",
    "    # store = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d65fe9-ea67-4038-b826-b3bc169c09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), store.as_retriever(), memory=memory, qa_prompt=QA_PROMPT,\n",
    "                                                     condense_question_prompt=CONDENSE_QUESTION_PROMPT, get_chat_history=get_chat_history)\n",
    "# qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), store.as_retriever(), memory=memory, get_chat_history=get_chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdc852-b9b2-4cf7-97e7-617c95819005",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    while True:\n",
    "        print(\"Human:\")\n",
    "        question = input()\n",
    "        if question.lower() == \"quit()\":\n",
    "            question = None\n",
    "            break\n",
    "        if question.lower() == \"clear_history()\":\n",
    "            qa.memory.clear()\n",
    "            question = None\n",
    "            continue\n",
    "        if question is not None and question != \"\" :\n",
    "            print(\"AI:\")\n",
    "            print(qa.run(question))\n",
    "                \n",
    "print(f\"Total Tokens: {cb.total_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
